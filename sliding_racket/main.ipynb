{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "injured-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import stat\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim \n",
    "from torch import nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import gym\n",
    "import gym.spaces\n",
    "import torch\n",
    "import torch.nn as nn        # Pytorch neural network package\n",
    "import torch.optim as optim  # Pytorch optimization package\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "from Environment import *\n",
    "from experience_replay import *\n",
    "from brain import *\n",
    "from agent import *\n",
    "from Hyperparameters import *\n",
    "# from ai import *\n",
    "# from gymWrappers import *\n",
    "# from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "duplicate-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = Hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "still-depression",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REPLAY_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2b616e87df6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGESIZE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGESIZE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mjimi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# jimi.loadKnowlage('best.dat')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\codes\\Deep-Reinforcement-Learning\\sliding_racket\\agent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargetNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperienceReplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREPLAY_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REPLAY_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "rewards = collections.deque(maxlen=20)\n",
    "\n",
    "\n",
    "env = Environment(param.IMAGESIZE[0],param.IMAGESIZE[1])\n",
    "jimi = Agent()\n",
    "# jimi.loadKnowlage('best.dat')\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for itr in range(param.ITER_NUM):\n",
    "    for eps in range(param.EPISODE_NUM):\n",
    "\n",
    "        action = jimi.find_action(state)\n",
    "        newState, reward, done= env.step(action)\n",
    "#         print(done)\n",
    "        jimi.giveFeedBack([state.clone(),action,reward,done,newState])\n",
    "        state = newState.clone()\n",
    "\n",
    "        if done:\n",
    "            print(f'iteration: {itr}, episode: {eps}, last_reward: {reward}, epsilon: {jimi.epsilon}, action: {action}')\n",
    "            state = env.reset()\n",
    "            jimi.reset()\n",
    "            break\n",
    "            \n",
    "    jimi.saveKnowlage(\"best.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "rewards = collections.deque(maxlen=20)\n",
    "state_list = []\n",
    "\n",
    "\n",
    "env = Environment(30,30)\n",
    "jimi = Agent()\n",
    "jimi.loadKnowlage('best.dat')\n",
    "jimi.epsilon = 0\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for itr in range(50):\n",
    "    for eps in range(50):\n",
    "        image = state[0].cpu().detach().numpy().copy()\n",
    "        image = (cv2.resize(image,(300,300))*255).astype(np.uint8)\n",
    "        state_list.append(np.expand_dims(image,axis=2))\n",
    "        cv2.imshow('game',image)\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "        action = jimi.find_action(state)\n",
    "        newState, reward, done= env.step(action)\n",
    "        state = newState.clone()\n",
    "\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            jimi.reset()\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surrounded-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file test.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "clip = ImageSequenceClip(state_list, fps=20)\n",
    "clip.write_gif('test.gif', fps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "developing-quilt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "processed-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "drawn-alexander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9216\n"
     ]
    }
   ],
   "source": [
    "model.get_conv_output_shape([1,3,30,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-foundation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
